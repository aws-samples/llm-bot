{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7f6f98-70f2-4ca6-b999-eed03641ea87",
   "metadata": {},
   "source": [
    "### 1. 安装HuggingFace 并下载模型到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f413314-c410-43d3-bb3a-ba0aa18ec1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface-hub -Uqq\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be112a00-cbef-4387-b0d7-80e5e7b7030d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # bge-en\n",
    "\n",
    "# from huggingface_hub import snapshot_download\n",
    "# from pathlib import Path\n",
    "\n",
    "# # local_model_path = Path(\"./buffer-embedding-002-model\")\n",
    "# local_model_path_name = \"./BAAI_bge_large_en_v1.5\"\n",
    "# model_hf_name = \"BAAI/bge-large-en-v1.5\"\n",
    "# model_name = model_hf_name.split('/')[-1]\n",
    "# commit_hash = \"5888da4a3a013e65d33dd6f612ecd4625eb87a7d\"\n",
    "\n",
    "# local_model_path = Path(local_model_path_name)\n",
    "# local_model_path.mkdir(exist_ok=True)\n",
    "# model_name = model_name\n",
    "# commit_hash = commit_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d99db-3518-4206-9134-dbda8a86ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge-zh\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# local_model_path = Path(\"./buffer-embedding-002-model\")\n",
    "local_model_path_name = \"./BAAI_bge_large_zh_v1.5\"\n",
    "model_hf_name = \"BAAI/bge-large-zh-v1.5\"\n",
    "model_name = model_hf_name.split('/')[-1]\n",
    "commit_hash = \"b5c9d86d763d9945f7c0a73e549a4a39c423d520\"\n",
    "\n",
    "local_model_path = Path(local_model_path_name)\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = model_name\n",
    "commit_hash = commit_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902798dc-227b-4191-ade7-b736571543ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snapshot_download(repo_id=model_hf_name, revision=commit_hash, cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3079f-a01d-42b8-9c90-0950cc9fa457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "name=\"ATL_UW2\"\n",
    "profile_name = os.environ[f\"{name}\"]\n",
    "%env AWS_DEFAULT_PROFILE = {profile_name}\n",
    "s3_bucket_name=os.environ[f\"{name}_S3_BUCKET_NAME\"]\n",
    "role=os.environ[f\"{name}_ROLE\"]\n",
    "s3_bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5c10f-ff86-4696-88ca-ce7ae038aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "currentDay = datetime.now().day\n",
    "currentMonth = datetime.now().month\n",
    "currentYear = datetime.now().year\n",
    "\n",
    "current_time = f\"{currentYear}{currentMonth}{currentDay}\"\n",
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9373d22-fde5-41f4-9a5f-d237c9b34240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b61ad8-a8c2-48c2-8539-e7c1e2afe773",
   "metadata": {},
   "source": [
    "### 2. 把模型拷贝到S3为后续部署做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1873f4-1bfe-4146-8297-584e9ad76fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "#role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "# bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "bucket = s3_bucket_name  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68394e44-4d51-48ae-adc1-d02f520a5d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_model_prefix = f\"aigc-embedding-models/{model_name}\"  # folder where model checkpoint will go\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_code_prefix = f\"aigc-embedding-models/{model_name}_deploy_code\"\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e177a-886d-4838-891e-2e612a3cbc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f35a6f-5988-42ec-87b0-de36eaebe41b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. 模型部署准备（entrypoint脚本，容器镜像，服务配置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86daea77-a7ae-46b8-8800-212d07ce5605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.3-cu117\"\n",
    ")\n",
    "\n",
    "#中国区需要替换为下面的image_uri\n",
    "# inference_image_uri = (\n",
    "#     f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.21.0-deepspeed0.8.3-cu117\"\n",
    "# )\n",
    "\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49435172-e6c5-492a-8dcb-43e3fffb0f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_code_dir = s3_code_prefix.split('/')[-1]\n",
    "!mkdir -p {local_code_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70990dd3-431e-4dd0-a494-d26ceb454945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {local_code_dir}/model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--device={device}')\n",
    "\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location, trust_remote_code=True)\n",
    "    tokenizer.padding_side = 'right'\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_location, \n",
    "        # device_map=\"balanced_low_0\", \n",
    "        trust_remote_code=True\n",
    "    ).half()\n",
    "    # load the model on GPU\n",
    "    model.to(device) \n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "generator = None\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0].to(device) #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float().to(device)\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer\n",
    "    if not model:\n",
    "        model, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    input_sentences = data[\"inputs\"]\n",
    "    logging.info(f\"inputs: {input_sentences}\")\n",
    "    \n",
    "    encoded_input = tokenizer(input_sentences, padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    # sentence_embeddings = model_output.cpu().numpy()\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1).cpu().numpy()\n",
    "\n",
    "#     # preprocess\n",
    "#     input_ids = tokenizer(input_sentences, return_tensors=\"pt\").input_ids\n",
    "#     # pass inputs with all kwargs in data\n",
    "#     if params is not None:\n",
    "#         outputs = model.generate(input_ids, **params)\n",
    "#     else:\n",
    "#         outputs = model.generate(input_ids)\n",
    "\n",
    "#     # postprocess the prediction\n",
    "#     prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    result = {\"sentence_embeddings\": sentence_embeddings}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a0f2a-a8d6-4134-a727-c5c0f1ad092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3://{bucket}/{s3_model_prefix}/\"\n",
    "print(f\"option.s3url ==> {s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1ecec-79cf-4ed4-bba1-95e2fe79daea",
   "metadata": {},
   "source": [
    "#### Note: option.s3url 需要按照自己的账号进行修改, 可以拷贝上一个cell的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ee385-5c6c-493c-bd40-9b57ae0c8e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {local_code_dir}/serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "# option.s3url = fs3://sagemaker-us-west-2-316327952690/LLM-RAG/workshop/buffer-embedding-002-model/\n",
    "option.s3url = S3PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833ea40-883c-4df8-9f9d-611c5a04ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i \"s|option.s3url = S3PATH|option.s3url = {s3_path}|\" {local_code_dir}/serving.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589ea47-5d1c-4791-a128-558d8e7e13ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm s2e_model.tar.gz\n",
    "!cd {local_code_dir} && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf s2e_model.tar.gz {local_code_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabd7ce-b855-4569-857c-ad872662800b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_artifact = sess.upload_data(\"s2e_model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb01ed-6bd3-4880-a647-cfd71e692820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. 创建模型 & 创建endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6209d24-8473-4256-93d3-02e4e144386b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(f\"{model_name}\").replace('.','-').replace('_','-')# name_from_base(\"st-paraphrase-mpnet-base-v2\") Note: Need to specify model_name\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49970f-3d4d-41f1-ba1e-abfd378de150",
   "metadata": {},
   "source": [
    "#### 推理机型选择 (https://aws.amazon.com/cn/sagemaker/pricing/)\n",
    "- GPU\n",
    "  + ml.g4dn.xlarge 按需价格 0.526 USD/Hour\n",
    "- CPU\n",
    "  + ml.c5.xlarge   按需价格 0.204 USD/Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686abae8-5db7-4ebd-9fbf-5bd54f36c0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 15*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190501e-639b-4dde-9f1f-781f06a6fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1df06-ae4a-42e2-9695-da0afa9ad734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag=f\"{current_time}-{commit_hash}\"\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name, Tags=[{\"Key\":\"version\", \"Value\":tag}],\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c71240-6878-4fed-bf7d-2c1cf75f4ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddba20e-fc18-480d-9940-ae39695ac450",
   "metadata": {},
   "source": [
    "### 5. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28db25-6996-440c-b004-14f96cfd982d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vector_by_sm_endpoint(questions, sm_client, endpoint_name):\n",
    "    parameters = {\n",
    "        # \"early_stopping\": True,\n",
    "        # \"length_penalty\": 2.0,\n",
    "        \"max_new_tokens\": 50,\n",
    "        \"temperature\": 0,\n",
    "        \"min_length\": 10,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "    }\n",
    "\n",
    "    response_model = sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": questions,\n",
    "            }\n",
    "        ),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    json_str = response_model['Body'].read().decode('utf8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    embeddings = json_obj['sentence_embeddings']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a40991-cb73-4635-b345-481d48dc7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。', 'Title:有关Oracle\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的rdsadmin语法请求帮助。 Content:这似乎是那些没有被文档化为\"通用示例\"的特定命令之一，当然我们无法查看rdsadmin_util软件包中的过程。至于邮件服务器，它的解析源是URL而不是IP地址。谢谢。 Answer:你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserve', '在本地环境中，最佳的处理数据库的方式是什么？ ', '我们目前正在使用Aurora RDS postgres数据库。最初，我们的数据库很小，容易管理，我们将转储发送到S3并提供给开发人员开发新功能和解决错误。  目前我们的数据库重达700GB，**最好的策略是什么，以便开发人员可以获得数据？**下载整个数据库是不可能的，这将浪费大量时间成本。最重要的是，开发人员能够获得数据库的副本来构建开发环境，以支持他们开发新功能和解决缺陷。 ', '首先，考虑一下是否拥有一个所有开发人员都连接的单个副本可以满足您的需求。他们可以远程连接，并且它将是您生产数据的一个副本。因此，它非常棒，因为很容易定期更新并保证覆盖所有生产用例。它有很多优势。  但这可能不能满足您的需求。您说您需要本地数据库。在这种情况下，我认为您有两条主要路径要考虑。  1. 生成示例数据 2. 创建提取生产数据子集的过程  在开始时，生成示例数据可能需要更多的工作。但它有一些不错的优点。很容易确保您生成所需的数据。它将是参数化的，因此每个开发人员在那个时刻生成他/她关心的数据。下载大数据集没有网络问题。  但如果您确实需要提取主数据库的一部分，那么您需要将其视为提取-转换-加载(ETL)项目。使用数据集成(DI/ETL)工具连接到主数据库并提取一些子集。理想情况下，子集将很容易定义。也许对于大多数表，您只需取最近2个月的数据，对于其他表(如参考表)，则取整个表。定义所有单个映射可能需要很大的努力...但实际上并不复杂。您可以决定详细信息，如将数据加载到另一个数据库或保存到CSV文件中。然后使数据库转储或CSV文件可供您的开发人员使用。作为一名开发人员，您可能会倾向于编写自己的脚本来执行']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7ff4e-4dd8-4df3-b4f0-aecdaf54a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_all = [sent[:512] for sent in sentences]\n",
    "\n",
    "endpoint_name = \"bge-large-zh-v1-5-2023-11-15-06-52-26-105-endpoint\"\n",
    "\n",
    "res = get_vector_by_sm_endpoint(sent_all, smr_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a38c7-65fc-4122-84f6-b4bf614497e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2401a-198c-47bd-a4b2-ebf21c86a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for zh endpoint\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = \"bge-large-zh-v1-5-2023-11-15-06-52-26-105-endpoint\"\n",
    "\n",
    "\n",
    "cand1 = []\n",
    "cand1.append(\"AWS提供的关键服务有哪些，以支持不同类型的企业需求和工作负载？\")\n",
    "cand1.append(\"Amazon SageMaker提供哪些关键功能，以支持企业在机器学习领域的需求和挑战？\")\n",
    "cand2 = []\n",
    "cand2.append(\"AWS的全球基础架构是如何支持高可靠性和可扩展性，以满足企业的云计算需求？\")\n",
    "cand2.append(\"Amazon SageMaker如何简化机器学习模型的开发、训练和部署过程，以提高企业的生产效率和创新能力？\")\n",
    "\n",
    "cand = cand1 + cand2\n",
    "\n",
    "res = get_vector_by_sm_endpoint(cand, smr_client, endpoint_name)\n",
    "\n",
    "cand1_embed = res[0:2]\n",
    "cand2_embed = res[2:]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for idx1, cand1_score in enumerate(cand1_embed):\n",
    "    for idx2, cand2_score in enumerate(cand2_embed):\n",
    "        # print(cand2_score)\n",
    "        print(f\"{cand1[idx1]}\")\n",
    "        print(f\"{cand2[idx2]}\") \n",
    "        print(f\"score: {np.dot(np.array(cand1_score), np.array(cand2_score).T)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7b9e2-b0cd-4f95-bfb4-b3ad27edd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for en endpoint\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = \"bge-large-en-v1-5-2023-11-15-06-19-29-526-endpoint\"\n",
    "\n",
    "\n",
    "cand1 = []\n",
    "cand1.append(\"What are some key advantages of adopting AWS for cloud computing compared to traditional on-premises infrastructure?\")\n",
    "cand1.append(\"What are the key advantages of using Amazon SageMaker for machine learning compared to traditional ML development workflows?\")\n",
    "cand2 = []\n",
    "cand2.append(\"Can you explain the main benefits that businesses can gain by leveraging AWS services for their cloud computing needs?\")\n",
    "cand2.append(\"How does Amazon SageMaker simplify the process of building, training, and deploying machine learning models compared to traditional approaches?\")\n",
    "\n",
    "cand = cand1 + cand2\n",
    "\n",
    "res = get_vector_by_sm_endpoint(cand, smr_client, endpoint_name)\n",
    "\n",
    "cand1_embed = res[0:2]\n",
    "cand2_embed = res[2:]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for idx1, cand1_score in enumerate(cand1_embed):\n",
    "    for idx2, cand2_score in enumerate(cand2_embed):\n",
    "        # print(cand2_score)\n",
    "        print(f\"{cand1[idx1]}\")\n",
    "        print(f\"{cand2[idx2]}\") \n",
    "        print(f\"score: {np.dot(np.array(cand1_score), np.array(cand2_score).T)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4f56a-092e-4a6a-a920-48550ec9f20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts1 = \"\"\"请问AWS Clean Rooms是多方都会收费吗？\"\"\"\n",
    "\n",
    "res = get_vector_by_sm_endpoint([prompts1], smr_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a39ad-697c-4dec-ba52-11cd5e5f9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts1 = \"\"\"What is the purpose of Amazon S3 in AWS, and how is it typically used?\"\"\"\n",
    "\n",
    "res = get_vector_by_sm_endpoint([prompts1], smr_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2249b-52f7-4153-960d-7019210ab85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
