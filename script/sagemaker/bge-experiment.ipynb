{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7f6f98-70f2-4ca6-b999-eed03641ea87",
   "metadata": {},
   "source": [
    "### 1. Using HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be112a00-cbef-4387-b0d7-80e5e7b7030d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "model = AutoModel.from_pretrained('infgrad/stella-base-zh-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('infgrad/stella-base-zh-v2')\n",
    "sentences = [\"数据1\", \"数据ABCDEFGH\"]\n",
    "batch_data = tokenizer(\n",
    "    batch_text_or_text_pairs=sentences,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=1024,\n",
    "    truncation=True,\n",
    ")\n",
    "attention_mask = batch_data[\"attention_mask\"]\n",
    "model_output = model(**batch_data)\n",
    "last_hidden = model_output.last_hidden_state.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "vectors = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "vectors = normalize(vectors, norm=\"l2\", axis=1, )\n",
    "print(vectors.shape)  # 2,768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623f5f2d-2764-4d6f-9f97-55631032d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。', 'Title:有关Oracle\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的rdsadmin语法请求帮助。 Content:这似乎是那些没有被文档化为\"通用示例\"的特定命令之一，当然我们无法查看rdsadmin_util软件包中的过程。至于邮件服务器，它的解析源是URL而不是IP地址。谢谢。 Answer:你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserve', '在本地环境中，最佳的处理数据库的方式是什么？ ', '我们目前正在使用Aurora RDS postgres数据库。最初，我们的数据库很小，容易管理，我们将转储发送到S3并提供给开发人员开发新功能和解决错误。  目前我们的数据库重达700GB，**最好的策略是什么，以便开发人员可以获得数据？**下载整个数据库是不可能的，这将浪费大量时间成本。最重要的是，开发人员能够获得数据库的副本来构建开发环境，以支持他们开发新功能和解决缺陷。 ', '首先，考虑一下是否拥有一个所有开发人员都连接的单个副本可以满足您的需求。他们可以远程连接，并且它将是您生产数据的一个副本。因此，它非常棒，因为很容易定期更新并保证覆盖所有生产用例。它有很多优势。  但这可能不能满足您的需求。您说您需要本地数据库。在这种情况下，我认为您有两条主要路径要考虑。  1. 生成示例数据 2. 创建提取生产数据子集的过程  在开始时，生成示例数据可能需要更多的工作。但它有一些不错的优点。很容易确保您生成所需的数据。它将是参数化的，因此每个开发人员在那个时刻生成他/她关心的数据。下载大数据集没有网络问题。  但如果您确实需要提取主数据库的一部分，那么您需要将其视为提取-转换-加载(ETL)项目。使用数据集成(DI/ETL)工具连接到主数据库并提取一些子集。理想情况下，子集将很容易定义。也许对于大多数表，您只需取最近2个月的数据，对于其他表(如参考表)，则取整个表。定义所有单个映射可能需要很大的努力...但实际上并不复杂。您可以决定详细信息，如将数据加载到另一个数据库或保存到CSV文件中。然后使数据库转储或CSV文件可供您的开发人员使用。作为一名开发人员，您可能会倾向于编写自己的脚本来执行']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5a39ad-697c-4dec-ba52-11cd5e5f9da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--device=cuda:0\n",
      "[2023-11-24 03:10:06,892] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--device={device}')\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-zh-v1.5')\n",
    "tokenizer.padding_side = 'right'\n",
    "model = AutoModel.from_pretrained('BAAI/bge-large-zh-v1.5').half()\n",
    "\n",
    "model.to(device) \n",
    "model.requires_grad_(False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99901992-378d-44a7-8199-0294f1918207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。你分享的信息显示你想查看语法\"ALTER SYSTEM SET SMTP_OUT_SERVER =…\"的文档？  从RDS Oracle公共文档进一步研究，我能找到：[+]<https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Options.UTLMAIL.html>  SMTP_OUT_SERVER是一个客户可以设置的参数。为了更改系统，客户需要修改该参数。  \"您可以使用DB参数组为DB实例设置默认SMTP_OUT_SERVER。您可以通过在DB实例上运行以下代码来为会话设置SMTP_OUT_SERVER参数。   ALTER SESSION SET smtp_out_server = mailserver.domain.com:25 ;\"  希望以上内容有所帮助。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_all = [sent[:512] for sent in sentences]\n",
    "sent = sent_all[0]\n",
    "sent = [sent_all[0]*10]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a2c337-2443-41ea-a5c7-dfde5d01a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2162) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Compute token embeddings\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     model_output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoded_input)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     sentence_embeddings \u001b[39m=\u001b[39m model_output[\u001b[39m0\u001b[39m][:, \u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Perform pooling. In this case, cls pooling\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225079746f7263682d4750552d5562756e74752d555732227d/home/ubuntu/py_gpu_ubuntu_uw2_workplace/csdc/llm-bot/script/sagemaker/bge-experiment.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Perform pooling. In this case, max pooling.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1015\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1018\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1019\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:238\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    237\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[0;32m--> 238\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[1;32m    239\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[1;32m    240\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2162) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentall, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "# for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "#     sentence_embeddings = model_output[0][:, 0]\n",
    "#     # Perform pooling. In this case, cls pooling\n",
    "\n",
    "# # Perform pooling. In this case, max pooling.\n",
    "# sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1).cpu().numpy()\n",
    "# print(\"Sentence embeddings:\", sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_input.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192c785-7b3c-496d-9107-b6162f4b43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sent[:512], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    # for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "    # encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "        # Perform pooling. In this case, cls pooling\n",
    "    \n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1).cpu().numpy()\n",
    "    print(\"Sentence embeddings:\", sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
